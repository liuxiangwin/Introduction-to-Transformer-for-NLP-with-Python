{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Token classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The task of classifying each token in a token sequence is called token classification. This task says that a specific model must be able to classify each token into a class. POS and NER are 2 of the most well-known tasks in this criterion. However, QA is also another major NLP task that fits in this category.\n",
        "\n",
        "# NER\n",
        "One of the well-known takss in the category of token classification is NER- the recognition of each token as an entity or not and identifying the type of each detected entity. For example a text can contain multiple entities at the same time- person names, locations, organizations and other types of entitties.\n",
        "\n",
        "It is a time to look at the example\n",
        "\n",
        "George Washington is one the presidents of the United States of America.\n",
        "\n",
        "George Washington is a person name while the United States of America is a location name. A sequence taggong model is expected to tag each word in the form of tags, each containing information about tag. BIO's tags are the ones that are universally used for standard NER tasks.\n",
        "\n",
        "# POS tagging\n",
        "\n",
        "POS tagging or grammar tagging is annotating a word in a given text according ot its respective part of speech. As a simple example, in a given text, identification of each word's role in the categories of noun, adjective, adverb and verb is considered to be POS. However, from a linguistic perspective, there are many roles other than these 4.\n",
        "\n",
        "# Understand QA\n",
        "A QA or reading comprehension task contains a set of reading comprehension texts with respective questions on them. An examplary dataset is SQUAD or Stanford Question Answering Dataset. This dataset contains Wikipedia texts and respective questions asked about them. The answers are in the form of segments of the original Wikipedia text."
      ],
      "metadata": {
        "id": "6qyU_sGd46sP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JbMN3qF4VS2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}