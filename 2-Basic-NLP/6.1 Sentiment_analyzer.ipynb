{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analyzer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis is the process of determining the sentiment of a piece of text. For example, it cna be used to determine whether a movie review is positive or negative. We can add more category as well. This technique can be used to get sensse of how people feel about a product, brand or topic. It is frequently used to analyze marketing campaigns, opinion polls, social media presence, product reviews on e-commerce sites and so on.\n",
        "\n",
        "Naive Bayes classifier will be used to build this sentiment analyzer. The first step will be all the unique word will be extracted from the text. The NLTK classifier needs this data to be arranged in the form of dictionary so that it can ingest. Once the text data is divided into training and testing datasets, the Naive Bayes classifier will be trained to classify the reviews into positive and negative. Afterward, the top most informative words to indiate positive and negative reviews can be calculated and displayed. This information is interesting because it shows what words ca beingused to denote various reactions."
      ],
      "metadata": {
        "id": "FDQVMOBPVAZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cu2kkmG0rAV1"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify.util import accuracy as nltk_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to construct a dictionary object based on the input words and return it\n",
        "def extract_features(words):\n",
        "  return dict([(word,True) for word in words])"
      ],
      "metadata": {
        "id": "w7grxDW5WYzT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('movie_reviews')\n",
        "# Load the reviews from corpus\n",
        "fileids_pos = movie_reviews.fileids('pos')\n",
        "fileids_neg = movie_reviews.fileids('neg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjrCtTG2WtCS",
        "outputId": "854ba5e2-91ff-4a67-ca2e-3142fb682dd3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features from the reviews\n",
        "features_pos = [(extract_features(movie_reviews.words(\n",
        "        fileids=[f])), 'Positive') for f in fileids_pos]\n",
        "features_neg = [(extract_features(movie_reviews.words(\n",
        "        fileids=[f])), 'Negative') for f in fileids_neg]"
      ],
      "metadata": {
        "id": "6D5kqdXwW9G9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is the define the split between training and testing. In this project we will alloate 80% for training and 20% for testing."
      ],
      "metadata": {
        "id": "7ItHKUQdXhMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the train and test split(80% and 20%)\n",
        "threshold = 0.8\n",
        "num_pos = int(threshold* len(features_pos))\n",
        "num_neg = int(threshold* len(features_neg))"
      ],
      "metadata": {
        "id": "JSQ5sPELXqtp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate the feature vectors for training and testing\n",
        "features_train = features_pos[:num_pos]+features_neg[:num_neg]\n",
        "features_test = features_pos[num_pos:]+features_neg[num_neg:]"
      ],
      "metadata": {
        "id": "USQSIWduX6Xk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of datapoints used\n",
        "print('\\nNumber of training datapoints:', len(features_train)) # len of the training dataset\n",
        "print('Number of test datapoints:', len(features_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7yt5M-VYNa1",
        "outputId": "01efaec6-1ff5-4769-9c39-7d3c07455c00"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of training datapoints: 1600\n",
            "Number of test datapoints: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we need to train a NaiveBayesClassifier using the training data and compute the accuracy using the inbuilt accuracy method available in NLTK"
      ],
      "metadata": {
        "id": "ej4hN02EYfUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = NaiveBayesClassifier.train(features_train)\n",
        "print('\\n Accuracy of the classifier:', nltk_accuracy(classifier, features_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LVFFbEpYpM2",
        "outputId": "370b7799-c78b-4abb-92e1-7668c16625de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Accuracy of the classifier: 0.735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the top N most informative words\n",
        "N = 15\n",
        "print('\\nTop ' + str(N) + ' most informative words:')\n",
        "for i, item in enumerate(classifier.most_informative_features()):\n",
        "    print(str(i+1) + '. ' + item[0])\n",
        "    if i == N - 1:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdvpaOwRY3lp",
        "outputId": "71b9786e-f03c-4fd4-9de0-53b20a4b40bf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 15 most informative words:\n",
            "1. outstanding\n",
            "2. insulting\n",
            "3. vulnerable\n",
            "4. ludicrous\n",
            "5. uninvolving\n",
            "6. astounding\n",
            "7. avoids\n",
            "8. fascination\n",
            "9. affecting\n",
            "10. animators\n",
            "11. anna\n",
            "12. darker\n",
            "13. seagal\n",
            "14. symbol\n",
            "15. idiotic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sample sentences to be used for testing\n",
        "input_reviews = [\n",
        "        'The costumes in this movie were great', \n",
        "        'I think the story was terrible and the characters were very weak',\n",
        "        'People say that the director of the movie is amazing', \n",
        "        'This is such an idiotic movie. I will not recommend it to anyone.' \n",
        "    ]\n"
      ],
      "metadata": {
        "id": "y2DOLh9JZaya"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the sample data and predict the output\n",
        "print(\"\\n Movie review predictions: \")\n",
        "for review in input_reviews:\n",
        "  print(\"\\nReview: \", review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tow0jn6Znnx",
        "outputId": "8f766b81-3563-40f5-d965-20071e7c2f2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Movie review predictions: \n",
            "\n",
            "Review:  The costumes in this movie were great\n",
            "\n",
            "Review:  I think the story was terrible and the characters were very weak\n",
            "\n",
            "Review:  People say that the director of the movie is amazing\n",
            "\n",
            "Review:  This is such an idiotic movie. I will not recommend it to anyone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import probability\n",
        "# Compute the probability for each class\n",
        "probabilities = classifier.prob_classify(extract_features(review.split()))\n",
        "# pick the maximum value\n",
        "predicted_sentiment = probabilities.max()\n",
        "#Print the predicted output class (positive or negative sentiment)\n",
        "print(\"Predicted sentiment: \", predicted_sentiment)\n",
        "print('Probabilities: ', round(probabilities.prob(predicted_sentiment), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdjcA2ssZ8t9",
        "outputId": "7825e6fb-7671-4381-a529-196f91210bc7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sentiment:  Negative\n",
            "Probabilities:  0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for review in input_reviews:\n",
        "    print(\"\\nReview:\", review)\n",
        "\n",
        "     # Compute the probabilities\n",
        "    probabilities = classifier.prob_classify(extract_features(review.split()))\n",
        "\n",
        "        # Pick the maximum value\n",
        "    predicted_sentiment = probabilities.max()\n",
        "\n",
        "        # Print outputs\n",
        "    print(\"Predicted sentiment:\", predicted_sentiment)\n",
        "    print(\"Probability:\", round(probabilities.prob(predicted_sentiment), 2))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUWc_tF3amQs",
        "outputId": "5386d3ec-034e-45cd-9bac-1f89b62edbf2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Review: The costumes in this movie were great\n",
            "Predicted sentiment: Positive\n",
            "Probability: 0.59\n",
            "\n",
            "Review: I think the story was terrible and the characters were very weak\n",
            "Predicted sentiment: Negative\n",
            "Probability: 0.8\n",
            "\n",
            "Review: People say that the director of the movie is amazing\n",
            "Predicted sentiment: Positive\n",
            "Probability: 0.6\n",
            "\n",
            "Review: This is such an idiotic movie. I will not recommend it to anyone.\n",
            "Predicted sentiment: Negative\n",
            "Probability: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen from the above result, we  can see and verify intuitively that the predictions are correct."
      ],
      "metadata": {
        "id": "jzhyG6UEbDxd"
      }
    }
  ]
}